from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_validate
from sklearn.model_selection import train_test_split
import optuna
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

from MalwareDataFileRead import *


# 勾配ブースティング
class Objective_GBC:
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __call__(self, trial):
        # 探索対象のパラメータの設定
        max_depth = int(trial.suggest_loguniform("max_depth", 3, 19))
        max_features = trial.suggest_categorical("max_features", ["log2", "sqrt"])
        learning_rate = float(trial.suggest_loguniform("learning_rate", 1e-2, 1e-0))
        #criterion = trial.suggest_categorical("criterion", ["friedman_mse", "mse", "mae"])
        # Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2.
        # Criterion 'mae' was deprecated in v1.0 and will be removed in version 1.2.
        #criterion = trial.suggest_categorical("criterion", ["friedman_mse",])
        criterion = trial.suggest_categorical("criterion", ["squared_error", "absolute_error", "poisson"])

        # モデルの初期化
        model = GradientBoostingClassifier(
            max_depth=max_depth,
            max_features=max_features,
            learning_rate=learning_rate,
            criterion=criterion
        )

        scores = cross_validate(model,
                                X=self.x,
                                y=self.y,
                                cv=5,
                                n_jobs=-1)

        return scores['test_score'].mean()


# パラメータチューニング処理
def gradient_boosting_classifier_tuning():

    # データファイルの読み込み
    x_obj_2, y_obj, malware_dataset = malware_data_read()

    # データセットを訓練用とテス用に分割
    x_train, x_test, y_train, y_test = train_test_split(x_obj_2, y_obj, test_size=0.2, shuffle=True, random_state=101)

    # 探索の対象クラスを設定
    objective = Objective_GBC(x_test, y_test)
    study = optuna.create_study()

    # 1回のみ探索処理を実行
    study.optimize(objective, n_trials=1)

    # ベストのパラメータを出力
    print("params:", study.best_params)

    # ベストなパラメータを返送
    return study, x_train, x_test, y_train, y_test


# 勾配ブースティングの機械学習処理(パラメータチューニン済を前提とした処理)
def gradient_boosting_classifier_execute(study_obj, x_train, x_test, y_train, y_test):

    # パラメータチューニングで得られたパラメータを設定
    model = GradientBoostingClassifier(
        criterion=study_obj.best_params['criterion'],
        learning_rate=study_obj.best_params['learning_rate'],
        max_depth=study_obj.best_params['max_depth'],
        max_features=study_obj.best_params['max_features']
    )

    # モデルの訓練処理を実行
    model.fit(x_train, y_train)

    # テスト用のデータを使って予測処理を実行
    pred = model.predict(x_test)

    # 予測結果とテスト用のデータを使って正答率と混合配列を出力
    print("Accuracy: {:.5f} %".format(100 * accuracy_score(y_test, pred)))
    print(confusion_matrix(y_test, pred))
